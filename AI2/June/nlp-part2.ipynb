{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../css/thro.svg\" align=\"right\" width=\"200\">\n",
    " \n",
    "# Introduction to AI (PART II) - Natural Language Processing (NLP)\n",
    "\n",
    "## Lecture 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be applying the n-gram language models. We start with a file of 2307 titles of bachelor and master thesis at the TH Rosenheim and the TH Nürnberg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"head\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!head -5 data/theses.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, we use generated the 3-grams from this file using SRILM (http://www.speech.sri.com/projects/srilm/):\n",
    "\n",
    "<pre>% ngram-count -lm theses.arpa.gz -order 3 -text theses.txt</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"head\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!head -15 data/theses.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"tail\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!tail -10 data/theses.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we will be using the PyNLPl library to access these 3-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The FoLiA library pynlpl.formats.folia is being used but this version is now deprecated and is replaced by FoLiAPy (pip install folia), see https://github.com/proycon/foliapy. Please update your software if you are a developer, if you are an end-user you can safely ignore this message.\n"
     ]
    }
   ],
   "source": [
    "# We use pynlpl ('pineapple') - see https://pypi.org/project/PyNLPl/\n",
    "from pynlpl.lm.lm import ARPALanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/theses.arpa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mdl \u001b[38;5;241m=\u001b[39m \u001b[43mARPALanguageModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/theses.arpa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pynlpl\\lm\\lm.py:207\u001b[0m, in \u001b[0;36mARPALanguageModel.__init__\u001b[1;34m(self, filename, encoding, encoder, base_e, dounknown, debug, mode)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    205\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    208\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/theses.arpa'"
     ]
    }
   ],
   "source": [
    "mdl = ARPALanguageModel('data/theses.arpa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how long the n-grams are (i.e. what the \"n\" is)\n",
    "mdl.order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the n-grams and their probabilities (in log-scale)\n",
    "mdl.ngrams._data\n",
    "# this is a dict of tupels (1 to 3 tokens) as key and 2-tupels containing the log-prop and (sometimes) a backoff-value,\n",
    "# which we will not be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the n-grams and their probabilities (in log-scale)\n",
    "# items() is a python function returning (key,value) tupels for a dict\n",
    "for x in mdl.ngrams._data.items():\n",
    "    print(x[0], '-->', x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find next tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a function to return the next most probable words for a text\n",
    "def findnexts(text, mdl, n=0):\n",
    "    # split the text into tokens\n",
    "    if isinstance(text, str):\n",
    "        hist = text.split()\n",
    "        hist = tuple(hist)\n",
    "    else:\n",
    "        hist = text\n",
    "    \n",
    "    # if the hist contains more tokens than the order of our n-grams, only use the last n tokens\n",
    "    if len(hist) >= mdl.order:\n",
    "        hist = hist[-mdl.order+1:]\n",
    "    \n",
    "    def match(x, h):\n",
    "        if not h:\n",
    "            return len(x[0]) == 1\n",
    "        else:\n",
    "            # history needs to be \"one longer\" but needs to match\n",
    "            return len(x[0]) == len(h) + 1 and x[0][:len(h)] == h\n",
    "    \n",
    "    cand = list(filter(lambda x: match(x, hist), mdl.ngrams._data.items()))\n",
    "    \n",
    "    # if no cands, shorten history from the left\n",
    "    while not cand:\n",
    "        hist = hist[1:]\n",
    "        cand = list(filter(lambda x: match(x, hist), mdl.ngrams._data.items()))\n",
    "        \n",
    "    cand = list(sorted(cand, key=lambda x: x[1][0], reverse=True))\n",
    "    \n",
    "    if n > 0:\n",
    "        return cand[:n]\n",
    "    else:\n",
    "        return cand\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findnexts(\"\", mdl, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findnexts(\"Design und Implementierung\", mdl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findnexts(\"und Implementierung\", mdl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findnexts(\"Analyse\", mdl, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive thesis titel completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaktive vervollständigung\n",
    "hist = []\n",
    "while True:\n",
    "    a = input().strip()\n",
    "    if not a:\n",
    "        break\n",
    "    hist.append(a)\n",
    "    print(' '.join(hist) + str(list(map(lambda x: x[0][-1], findnexts(' '.join(hist), mdl)))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic thesis titel generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_titles(max_len=20):\n",
    "    hist = ('<s>')\n",
    "    title = []\n",
    "    for i in range(max_len):\n",
    "        cand = findnexts(hist, mdl)\n",
    "        if not cand:\n",
    "            break\n",
    "\n",
    "        cand = random.choice(cand)[0]\n",
    "\n",
    "        if cand[-1] == '</s>':\n",
    "            break\n",
    "            \n",
    "        title.append(cand[-1])\n",
    "        hist = cand\n",
    "    return title\n",
    "\n",
    "for i in range(8):\n",
    "    print('*',' '.join(generate_titles()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EOF ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
