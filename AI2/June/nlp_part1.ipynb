{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eGcr5FOjcI4"
   },
   "source": [
    "<img src=\"../css/thro.svg\" align=\"right\" width=\"200\"> \n",
    "\n",
    "# Introduction to AI (PART II) - Natural Language Processing (NLP)\n",
    "\n",
    "## Lecture 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZNgRdq_jcI9"
   },
   "source": [
    "Now, let's use our nicely cleaned Wine Review dataset to find similar wine reviews. Each wine review is a list of terms. In order to find similar wine reviews, we therefore need to define a similarity measure on lists of terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSVqU2_ojcJA"
   },
   "source": [
    "---\n",
    "## Part 1 - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERbjo2E2jcJA"
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LsLprvbFjcJA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIuibFDxjcJB",
    "outputId": "393ff308-bf4a-479e-d587-90decd524cd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\Felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('webtext')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TwxNlgV3jcJC"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wines_lem.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read the preprocessed data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwines_lem.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m filehandle:\n\u001b[0;32m      3\u001b[0m     wines_lem \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(filehandle)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwine_lines.data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m filehandle:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wines_lem.data'"
     ]
    }
   ],
   "source": [
    "# read the preprocessed data\n",
    "with open('wines_lem.data', 'rb') as filehandle:\n",
    "    wines_lem = pickle.load(filehandle)\n",
    "\n",
    "with open('wine_lines.data', 'rb') as filehandle:\n",
    "    wine_lines = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32Slx6pLjcJC"
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8cwpVP3jcJC",
    "outputId": "0bd160ce-c0c2-4d41-b78b-b36572ead012"
   },
   "outputs": [],
   "source": [
    "# compute the word counts for each document\n",
    "cv=CountVectorizer(analyzer=lambda x:x)\n",
    "word_count_vector=cv.fit_transform(wines_lem)\n",
    "feature_names = cv.get_feature_names()\n",
    "print(word_count_vector.shape)\n",
    "\n",
    "show = 9\n",
    "# get count vector for one of the documents\n",
    "show_doc_vector=word_count_vector[show]\n",
    "\n",
    "# print the count\n",
    "df = pd.DataFrame(show_doc_vector.T.todense(), index=feature_names, columns=[\"count\"])\n",
    "print(wines_lem[show])\n",
    "print(df.sort_values(by=[\"count\"],ascending=False)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRnr8LvzjcJC",
    "outputId": "1a37c173-eb82-43f8-f3fc-6386a410f46a"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "# print the lowest and highest idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(), columns=[\"idf\"])\n",
    "print(df_idf.sort_values(by=['idf'])[:10])\n",
    "print(df_idf.sort_values(by=['idf'])[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJ0sBDpOjcJD"
   },
   "outputs": [],
   "source": [
    "# note that many of the very frequent words have low idf values, i.e. they appear in many\n",
    "# reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-hKXT3VjcJD",
    "outputId": "5f6f96c5-31c6-4956-c837-5ba5c74cf10b"
   },
   "outputs": [],
   "source": [
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(word_count_vector)\n",
    "\n",
    "show = 0\n",
    "# get tfidf vector for first document\n",
    "show_doc_vector=tf_idf_vector[show]\n",
    "\n",
    "#print the scores\n",
    "df = pd.DataFrame(show_doc_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "print(wines_lem[show])\n",
    "print(df.sort_values(by=[\"tfidf\"],ascending=False)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-Hbo5a9jcJD"
   },
   "source": [
    "# Compute similar wine reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eh8vC1qAjcJE"
   },
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(tf_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "8imUx4X6jcJE",
    "outputId": "cfba4638-8b15-49bf-ac53-eb9165f9584c"
   },
   "outputs": [],
   "source": [
    "index = 107\n",
    "df = pd.DataFrame(similarities[index], index=wine_lines, columns=[\"similarity\"])\n",
    "df['#']=np.arange(0, len(df))\n",
    "df.sort_values(by=[\"similarity\"],ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwa7F-kbjcJE"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-wi2E2BjcJE"
   },
   "source": [
    "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located close to one another in the space. [wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cbJPLj6jcJF"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cMJL-UnjcJF",
    "outputId": "2ea0cf56-57c9-4649-879e-d229cd35ee97"
   },
   "outputs": [],
   "source": [
    "# load a pretrained word embedding model - this one has 400.000 words with vectors of\n",
    "# length 50 and has been trained on the wikipedia from 2014 plus the Gigaword 5 dataset\n",
    "# see https://github.com/RaRe-Technologies/gensim-data\n",
    "# and https://catalog.ldc.upenn.edu/LDC2011T07\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ws3BwlIrjcJF",
    "outputId": "d1aa052a-ba69-4836-95a1-67ab09080384"
   },
   "outputs": [],
   "source": [
    "model['wine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF5Q5ZlRjcJF",
    "outputId": "6f3e09f0-2714-46f6-9a80-d2f457354ac0"
   },
   "outputs": [],
   "source": [
    "model.most_similar(\"wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzfwZpeRjcJF",
    "outputId": "b396afde-bf2e-4014-e5c7-457e3f2858aa"
   },
   "outputs": [],
   "source": [
    "print(len(model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m_I1uGwjcJG"
   },
   "outputs": [],
   "source": [
    "# remove all words not in the pre-trained vocabulary (nested list comprehension)\n",
    "wines_vo = [[w for w in wine if w in model.vocab] for wine in wines_lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "532AzjdvjcJG",
    "outputId": "3d129897-f73a-4f95-94e5-2208802b573b"
   },
   "outputs": [],
   "source": [
    "# check if there are \"empty\" wine reviews now, i.e. reviews without any words\n",
    "len([len(wine) for wine in wines_vo if len(wine)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJTzgOytjcJG",
    "outputId": "878cfe47-dae0-4e4e-8ec3-4053674f0e23"
   },
   "outputs": [],
   "source": [
    "# remove all these empty wine reviews (from both the word vectors and the original data)\n",
    "notempty = [len(wine)>0 for wine in wines_vo]\n",
    "wines_fwc = np.array(wines_vo)[notempty]\n",
    "wine_lines_fwc = np.array(wine_lines)[notempty]\n",
    "print(len(wines_fwc))\n",
    "print(len(wine_lines_fwc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJaggIRajcJG"
   },
   "outputs": [],
   "source": [
    "# compute the document vectors bei averaging the word vectors\n",
    "rr_wv = [np.mean([model[w] for w in r if w in model.vocab], axis=0) for r in wines_fwc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1FWwD9OjcJH",
    "outputId": "bc736a85-40de-494c-f852-75f093869839"
   },
   "outputs": [],
   "source": [
    "rr_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUN-9zPzjcJI"
   },
   "outputs": [],
   "source": [
    "# compute the cosine-similarity matrix\n",
    "sim_dv = cosine_similarity(rr_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WBCoP88fjcJI",
    "outputId": "95bdc1d2-e0d0-49f4-cf3e-bb567f6e9aa4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the most similar reviews for review # 100\n",
    "index = 100\n",
    "df = pd.DataFrame(sim_dv[index], index=wine_lines_fwc, columns=[\"similarity\"])\n",
    "df['#']=np.arange(0, len(df))\n",
    "df.sort_values(by=[\"similarity\"],ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TawypWJ7jcJI"
   },
   "outputs": [],
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp04-lecture_part2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
